{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "from arch import arch_model\n",
    "\n",
    "from ipywidgets import HBox, VBox, Dropdown, Output\n",
    "from scipy.optimize import fmin, minimize\n",
    "from scipy.stats import t\n",
    "from scipy.stats import norm\n",
    "from math import inf\n",
    "from IPython.display import display\n",
    "from scipy.linalg import sqrtm\n",
    "\n",
    "import bs4 as bs\n",
    "import requests\n",
    "import yfinance as yf\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic Conditional Correlation - What is it and why should you care?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns lower matrix as vector by rows\n",
    "def vecl(matrix): \n",
    "    lower_matrix = np.tril(matrix,k=-1)\n",
    "    array_with_zero=np.matrix(lower_matrix).A1\n",
    "   \n",
    "\n",
    "    array_without_zero = array_with_zero[array_with_zero!=0]\n",
    "\n",
    "    return array_without_zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return cdf of standerdized residuals with nu deg of freedom as vector of length T\n",
    "\n",
    "def garch_t_to_u(rets, res):\n",
    "    mu = res.params['mu']\n",
    "    nu = res.params['nu']\n",
    "    est_r = rets - mu\n",
    "    h = res.conditional_volatility\n",
    "    std_res = est_r /np.sqrt(h) #perhaps just h as h is altready standard deviation\n",
    "    udata = t.cdf(std_res, nu)\n",
    "    return udata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return log likelihood of L_c\n",
    "def loglike_norm_dcc_copula(theta, udata):\n",
    "    N, T = np.shape(udata)\n",
    "    llf = np.zeros((T,1))\n",
    "    trdata = np.array(norm.ppf(udata).T, ndmin=2) # p-value of one-tail test on cdf of t-distirbution on standardized residuals\n",
    "                                                  # ppf == oposite of cdf\n",
    "    \n",
    "    Rt, veclRt =  dcceq(theta,trdata)\n",
    "\n",
    "    for i in range(0,T):\n",
    "        llf[i] = -0.5* np.log(np.linalg.det(Rt[:,:,i]))\n",
    "        if (i % 10) ==0:\n",
    "            print('llf: {}, det {}, a is {} '.format(llf[i],np.linalg.det(Rt[:,:,i]), theta))\n",
    "        llf[i] = llf[i] - 0.5 *  np.matmul(np.matmul(trdata[i,:] , (np.linalg.inv(Rt[:,:,i]) - np.eye(N))) ,trdata[i,:].T)\n",
    "    llf = np.sum(llf)\n",
    "\n",
    "    return -llf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# calculate R_t and Q as in quation (1) return Rt and vech(R_t) - lower part of matrix as stacked vector \n",
    "def dcceq(theta,trdata):\n",
    "    T, N = np.shape(trdata)\n",
    "\n",
    "    a, b = theta\n",
    "    \n",
    "    if min(a,b)<0 or max(a,b)>1 or a+b > .999999:\n",
    "        a = .9999 - b\n",
    "        \n",
    "    Qt = np.zeros((N, N ,T))\n",
    "\n",
    "    Qt[:,:,0] = np.cov(trdata.T)\n",
    "  \n",
    "\n",
    "    Rt =  np.zeros((N, N ,T))\n",
    "    veclRt =  np.zeros((T, int(N*(N-1)/2)))\n",
    "    \n",
    "    Rt[:,:,0] = np.corrcoef(trdata.T)\n",
    "    print(Rt[:,:,0])\n",
    "    \n",
    "    for j in range(1,T):\n",
    "        Qt[:,:,j] = Qt[:,:,0] * (1-a-b)\n",
    "        Qt[:,:,j] = Qt[:,:,j] + a * np.matmul(trdata[[j-1]].T, trdata[[j-1]])\n",
    "        Qt[:,:,j] = Qt[:,:,j] + b * Qt[:,:,j-1]\n",
    "        Rt[:,:,j] = np.divide(Qt[:,:,j] , np.matmul(np.sqrt(np.array(np.diag(Qt[:,:,j]), ndmin=2)).T , np.sqrt(np.array(np.diag(Qt[:,:,j]), ndmin=2))))\n",
    "    \n",
    "    for j in range(0,T):\n",
    "        veclRt[j, :] = vecl(Rt[:,:,j].T)\n",
    "    return Rt, veclRt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #estimate univariate GARCH models and return parameters \n",
    "model_parameters = {}\n",
    "udata_list = []\n",
    "\n",
    "def run_garch_on_return(rets, udata_list, model_parameters):\n",
    "    for x in rets:\n",
    "        am = arch_model(rets[x], dist = 't')\n",
    "        short_name = x.split()[0]\n",
    "        model_parameters[short_name] = am.fit(disp='off')\n",
    "        udata = garch_t_to_u(rets[x], model_parameters[short_name])\n",
    "        udata_list.append(udata)\n",
    "    return udata_list, model_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initially run GARCH on the individual time series, and transform them to the uniform distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = requests.get('http://en.wikipedia.org/wiki/List_of_S%26P_500_companies')\n",
    "soup = bs.BeautifulSoup(resp.text, 'lxml')\n",
    "table = soup.find('table', {'class': 'wikitable sortable'})\n",
    "tickers = []\n",
    "for row in table.findAll('tr')[1:]:\n",
    "    ticker = row.findAll('td')[0].text\n",
    "    tickers.append(ticker)\n",
    "\n",
    "tickers = [s.replace('\\n', '') for s in tickers]\n",
    "start = datetime.datetime(2010,1,1)\n",
    "end = datetime.datetime(2020,12,30)\n",
    "close_prices = yf.download(tickers, start=start, end=end)['Adj Close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rets = ((close_prices / close_prices.shift(1)) - 1 ).dropna(how='all') * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "udata_list = []\n",
    "udata_list, model_parameters = run_garch_on_return(rets.iloc[:,:25].dropna(), udata_list, model_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#udata_list\n",
    "#rets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup our DDC Model, and then run it on our 5 securities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lambda functions definds that the following ineq must hold \n",
    "\n",
    "cons = ({'type': 'ineq', 'fun': lambda x:  -x[0]  -x[1] +1})\n",
    "bnds = ((0, 0.5), (0, 0.9997))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cons['fun']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%time opt_out = minimize(loglike_norm_dcc_copula, np.array([0.01, 0.95]), args = (udata_list,), bounds=bnds, constraints=cons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(opt_out.success)\n",
    "print(opt_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "udata_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llf  = loglike_norm_dcc_copula(opt_out.x, udata_list)\n",
    "llf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "udata_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trdata = np.array(norm.ppf(udata_list).T, ndmin=2)\n",
    "Rt, veclRt = dcceq(opt_out.x, trdata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_names = [x.split()[0] for x in rets.iloc[:,:50].columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_name_list = []\n",
    "for i, name_a in enumerate(stock_names):\n",
    "    if i == 0:\n",
    "        pass\n",
    "    else:\n",
    "        for name_b in stock_names[:i]:\n",
    "            corr_name_list.append(name_a + \"-\" + name_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ABBV (AbbVie) and A (Agilent Technologies) Look interesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcc_corr = pd.DataFrame(veclRt, index = rets.iloc[:,:50].dropna().index, columns= corr_name_list)\n",
    "dcc_plot = px.line(dcc_corr, title = 'Dynamic Conditional Correlation plot', width=1000, height=500)\n",
    "dcc_plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "garch_vol_df = pd.concat([pd.DataFrame(model_parameters[x].conditional_volatility/100)*1600 for x in model_parameters], axis=1)\n",
    "garch_vol_df.columns = stock_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(garch_vol_df, title='GARCH Conditional Volatility', width=1000, height=500).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(garch_vol_df, x = 'ABBV', y='A', width=1000, height=500, title='GARCH Volatility').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(np.log((1+rets.iloc[:,:5].dropna()/100).cumprod()), title='Cumulative Returns', width=1000, height=500).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rets.loc[:, ['ABBV','A']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_corr_data(change):\n",
    "    a1corr = rets.loc[:, pair_dropdown.value.split('-')].corr().values[0][1]\n",
    "    a1dcc = pd.DataFrame(veclRt[:,corr_name_list.index(pair_dropdown.value)],index = rets.iloc[:,:5].dropna().index)\n",
    "    a1dcc.columns = ['DCC']\n",
    "    a1dcc['corr'] = a1corr\n",
    "    corr_line_plot = px.line(a1dcc, title = 'DCC vs unconditional correlation for ' + pair_dropdown.value, width=1000, height=500)\n",
    "    output_graphics.clear_output()\n",
    "    with output_graphics:\n",
    "        display(corr_line_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_graphics = Output()\n",
    "pair_dropdown = Dropdown(options=[''] + corr_name_list)\n",
    "pair_dropdown.observe(update_corr_data, 'value')\n",
    "VBox([pair_dropdown, output_graphics])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sympy as sp\n",
    "from sympy import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(np.sqrt(np.array(x, ndmin = 2 )))\n",
    "np.array(x, ndmin = 2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[ 4,  8,  9], ##reg. matrix\n",
    "       [10, 10, 12],\n",
    "       [13, 14, 15]])\n",
    "x\n",
    "y = np.matmul(x.T,x) #symetric and P.D.\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "A = np.sqrt(np.array(np.diag(y), ndmin=2)).T \n",
    "B = np.sqrt(np.array(np.diag(y), ndmin=2))\n",
    "np.divide (y , np.matmul(A, B))\n",
    "A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = Matrix([sp.sqrt(q1),sp.sqrt(q5),sp.sqrt(q9)])\n",
    "Z * Z.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B_sqrt = B**(1/2)\n",
    "B_sqrt_inv = B_sqrt.inv(method =\"LU\")\n",
    "B_sqrt_inv * A * B_sqrt_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var('q1,q2,q3,q4,q5,q6,q7,q8,q9')\n",
    "\n",
    "A = Matrix([[q1,q2,q3],\n",
    "             [q4,q5,q6],\n",
    "             [q7,q8,q9]])\n",
    "B = Matrix([[q1,0,0],\n",
    "             [0,q5,0],\n",
    "             [0,0,q9]])\n",
    "C = B.inv(method = \"LU\")\n",
    "print(C)\n",
    "B*A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = np.array([[q1,q2,q3],\n",
    "             [q4,q5,q6],\n",
    "             [q7,q8,q9]])\n",
    "Q"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
